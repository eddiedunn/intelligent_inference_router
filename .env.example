# Intelligent Inference Router v2
# Copy to .env and fill in your values

# Router
IIR_API_KEY=your-api-key-here
IIR_LOG_LEVEL=INFO

# Bifrost (LLM gateway)
IIR_BIFROST_URL=http://localhost:8080

# Ollama (local models)
IIR_OLLAMA_URL=http://localhost:11434

# Redis (classification cache)
IIR_REDIS_URL=redis://localhost:6379/0

# Provider API keys (passed through to Bifrost)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GROQ_API_KEY=
