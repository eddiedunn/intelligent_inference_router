# Example .env for IIR MVP Phase 1a

# API Key for server authentication (replace with your generated key)
ROUTER_API_KEY=changeme

# Comma-separated list of allowed API keys (optional)
#ROUTER_ALLOWED_API_KEYS=key1,key2

# Redis connection string
# For Docker Compose: use the service name
REDIS_URL=redis://iir-redis:6379/0
# For local development/testing: uncomment the line below
# REDIS_URL=redis://localhost:6379/0

# Local vLLM endpoint (required for local model routing)
vllm_base_url=http://dummy

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Set to true to enable full content logging (useful for debugging, not for prod)
ROUTER_LOG_FULL_CONTENT=false

# Optional: Set to host:port (e.g., 1.2.3.4:9999) to forward logs via UDP for remote debugging
REMOTE_LOG_SINK=

# ---------- External LLM Providers ----------

# OpenAI
OPENAI_API_KEY=
OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_API_BASE=https://api.anthropic.com/v1

# Grok (xAI)
GROK_API_KEY=
GROK_API_BASE=https://api.grok.x.ai/v1

# OpenRouter
OPENROUTER_API_KEY=
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# OpenLLaMA (if using an API gateway)
OPENLLAMA_API_KEY=
OPENLLAMA_API_BASE=https://api.openllama.com/v1

# ---------- Caching Layer ----------

# Cache backend: 'simple' (in-memory, single process) or 'redis' (recommended for production)
CACHE_BACKEND=simple

# Default cache TTL (expiration) in seconds (e.g., 86400 = 24 hours)
CACHE_TTL_SECONDS=86400

# (Redis only) Cache eviction policy (e.g., allkeys-lru, allkeys-lfu, volatile-lru, etc.)
CACHE_EVICTION_POLICY=allkeys-lru

# (Optional) Per-category TTL overrides (JSON string, e.g. '{"text_generation": 3600, "image_recognition": 86400}')
CACHE_PER_CATEGORY_TTL=

vllm_base_url=http://dummy